import streamlit as st
import requests
from PIL import Image
from io import BytesIO
import numpy as np
import os
from source.toxicity import text2toxicity, load_model

model_path = "./models/toxicity.pt"
if os.path.exists(model_path):
    pass
else:
    st.error(
        f"–ú–æ–¥–µ–ª—å {model_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, —á—Ç–æ –∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ Streamlit."
    )
    st.stop()

model, tokenizer = load_model(model_path)

st.header("–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–µ–ø–µ–Ω–∏ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞")

st.divider()

st.subheader("–ü–æ–ø—Ä–æ–±—É–π –ø–æ–±–∏—Ç—å —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å 9.95üíÄüíÄüíÄ")


st.subheader("–í—ã–¥–∞–π —Å–∞–º–æ–µ –∑–ª–æ–µ, –Ω–∞ —á—Ç–æ —Ç—ã —Å–ø–æ—Å–æ–±–µ–Ω")

text = st.text_input("–ù–∞–ø–∏—à–∏ —Å–≤–æ–π —Å–∞–º—ã–π —Ç–æ–∫—Å–∏—á–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", "–Ø —É—á—É—Å—å –≤ –≠–ª—å–±—Ä—É—Å–µ")

st.divider()

toxic_value = text2toxicity(text=text, model=model, tokenizer=tokenizer)[0]*10

if toxic_value <= 2:
    st.markdown(f"""
    ### –î–∞ —Ç—ã –µ—â–µ –ª–∞–ø–æ—á–∫–∞üå∫
    """)
elif toxic_value <= 5:
    st.markdown("""
    ### –í–ø–æ–ª–Ω–µ —Å–µ–±–µ –æ–±—ã—á–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π üòä
    """)
elif toxic_value <= 8:
    st.markdown("""
    ### –ü–æ—Ö–æ–∂–µ —Ç—ã –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏–π –∑–Ω–∞–µ—à—å –±–æ–ª—å—à–µ, —á–µ–º –æ–±—ã—á–Ω—ã—Ö —Å–ª–æ–≤ üò°
    """)
elif toxic_value < 9.95:
    st.markdown("""
    ### –ß—É—Ç–æ—á–∫—É –Ω–µ –¥–æ—Ç—è–Ω—É–ª, –Ω–æ –¥–ª—è —Ç–µ–±—è —É–∂–µ –µ—Å—Ç—å –∫–æ—Ç–µ–ª –≤ –∞–¥—É üòà
    """)
else:
    st.markdown("""
    ### –í—ã –ø—Ä–æ—Å—Ç–æ —Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ, –ª—é–±–æ–π —Å–ø–æ—Ä –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –∑–∞ –≤–∞–º–∏ üíÄüíÄüíÄ
    """)

st.markdown(f"""
### –¢–≤–æ–π —É—Ä–æ–≤–µ–Ω—å —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ {toxic_value:.2f}
""")

