{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrey/Documents/venv/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# импортируем трансформеры\n",
    "import transformers\n",
    "from transformers import AdamW\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import source.train_rnn_aa as train_rnn_aa\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset, DataLoader, RandomSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "\n",
    "#some useful lybs\n",
    "import random as random\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Классный мастер. Огромное спасибо за чудесное ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Замечательный врач. Хочу выразить особую благо...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Благодарность работникам рентгена. Добрый вече...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Доктор Рабинович. Женщины советского образца в...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Есть кому сказать спасибо. У меня с детства оч...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Классный мастер. Огромное спасибо за чудесное ...      1\n",
       "1  Замечательный врач. Хочу выразить особую благо...      1\n",
       "2  Благодарность работникам рентгена. Добрый вече...      1\n",
       "3  Доктор Рабинович. Женщины советского образца в...      0\n",
       "4  Есть кому сказать спасибо. У меня с детства оч...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# читаемм данные\n",
    "train_df = pd.read_csv('data/short_set.csv', index_col=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Классный мастер. Огромное спасибо за чудесное ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Замечательный врач. Хочу выразить особую благо...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Благодарность работникам рентгена. Добрый вече...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Доктор Рабинович. Женщины советского образца в...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Есть кому сказать спасибо. У меня с детства оч...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Классный мастер. Огромное спасибо за чудесное ...    1.0\n",
       "1  Замечательный врач. Хочу выразить особую благо...    1.0\n",
       "2  Благодарность работникам рентгена. Добрый вече...    1.0\n",
       "3  Доктор Рабинович. Женщины советского образца в...    0.0\n",
       "4  Есть кому сказать спасибо. У меня с детства оч...    1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'] = train_df['label'].astype(float)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.rename(columns={'text':'content', 'label':'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! comment it when ready !!!!\n",
    "\n",
    "# limit the set for models setup time\n",
    "#data_limit = 0.04 # to 4% of original length\n",
    "#data_len = len(train_df)-1\n",
    "#a_len = round(data_len * data_limit)\n",
    "#\n",
    "#a = [random.randint(0, data_len) for i in range(a_len)] \n",
    "#train_df = train_df.iloc[ a , : ].reset_index(drop=True)\n",
    "#len(train_df) # 7060 records -> 10%\n",
    "#4% -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Классный мастер. Огромное спасибо за чудесное ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Замечательный врач. Хочу выразить особую благо...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Благодарность работникам рентгена. Добрый вече...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Доктор Рабинович. Женщины советского образца в...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Есть кому сказать спасибо. У меня с детства оч...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  class\n",
       "0  Классный мастер. Огромное спасибо за чудесное ...    1.0\n",
       "1  Замечательный врач. Хочу выразить особую благо...    1.0\n",
       "2  Благодарность работникам рентгена. Добрый вече...    1.0\n",
       "3  Доктор Рабинович. Женщины советского образца в...    0.0\n",
       "4  Есть кому сказать спасибо. У меня с детства оч...    1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "CUDA_VISIBLE_DEVICES = 0,1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/google-bert/bert-base-uncased\n",
    "# подгружаем токенизатор и модель\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "local_bert = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([44934., 16994.,  4948.,  1871.,   835.,   413.,   221.,   147.,\n",
       "          144.,    90.]),\n",
       " array([  3. ,  89.8, 176.6, 263.4, 350.2, 437. , 523.8, 610.6, 697.4,\n",
       "        784.2, 871. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# words number in set\n",
    "train_lens = [len(i.split()) for i in train_df['content']]\n",
    "plt.hist(train_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 550 #2048 max\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, train_labels, test_labels = train_test_split(train_df['content'], train_df['class'], \n",
    "                                                                    random_state=99, \n",
    "                                                                    test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train_df = tokenizer.batch_encode_plus(train_df.tolist(), max_length = SEQ_LEN, pad_to_max_length=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_test_df = tokenizer.batch_encode_plus(test_df.tolist(), max_length = SEQ_LEN, pad_to_max_length=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_tenzor = torch.tensor(tokens_train_df['input_ids'])\n",
    "train_mask_tenzor = torch.tensor(tokens_train_df['attention_mask'])\n",
    "train_y_tenzor = torch.from_numpy(np.array(train_labels))\n",
    "\n",
    "test_X_tenzor = torch.tensor(tokens_test_df['input_ids'])\n",
    "test_mask_tenzor = torch.tensor(tokens_test_df['attention_mask'])\n",
    "test_y_tenzor = torch.from_numpy(np.array(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_X_tenzor, train_mask_tenzor, train_y_tenzor)\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TensorDataset(test_X_tenzor, test_mask_tenzor, test_y_tenzor)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze it\n",
    "for param in local_bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_architecture(nn.Module):\n",
    "    def __init__(self, bert):     \n",
    "      super(BERT_architecture, self).__init__()\n",
    "      self.bert = bert \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout()      \n",
    "      self.tahn = nn.Tanh()\n",
    "      self.Sigmoid1 = nn.Sigmoid()\n",
    "      self.Sigmoid2 = nn.Sigmoid()\n",
    "      self.fc1 = nn.Linear(312,256)\n",
    "      self.fc2 = nn.Linear(256,100)\n",
    "      self.fc3 = nn.Linear(100,32)\n",
    "      self.fc4 = nn.Linear(32,1)\n",
    "      #self.fc3 = nn.Linear(64,5)\n",
    "\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "      \n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False) \n",
    "      cls_hs = nn.functional.normalize(cls_hs)\n",
    "      #print(f'cls : {cls_hs.shape}')  #cls : torch.Size([64, 312])\n",
    "      x = self.fc1(cls_hs)\n",
    "      x = self.Sigmoid1(x)\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      x = self.fc2(x)\n",
    "      x = self.Sigmoid2(x)\n",
    "\n",
    "      x = self.fc3(x)\n",
    "      x = self.Sigmoid2(x)\n",
    "      x = self.fc4(x)\n",
    "      x = self.Sigmoid2(x)\n",
    "      return x\n",
    "\n",
    "#Epoch 1, time spent: 5.22\n",
    "#train_loss : 0.1578 val_loss : 0.1602\n",
    "#train_accuracy : 0.94 val_accuracy : 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): BERT_architecture(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(83828, 312, padding_idx=0)\n",
       "        (position_embeddings): Embedding(2048, 312)\n",
       "        (token_type_embeddings): Embedding(2, 312)\n",
       "        (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-2): 3 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSdpaSelfAttention(\n",
       "                (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "                (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (tahn): Tanh()\n",
       "    (Sigmoid1): Sigmoid()\n",
       "    (Sigmoid2): Sigmoid()\n",
       "    (fc1): Linear(in_features=312, out_features=256, bias=True)\n",
       "    (fc2): Linear(in_features=256, out_features=100, bias=True)\n",
       "    (fc3): Linear(in_features=100, out_features=32, bias=True)\n",
       "    (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERT_architecture(local_bert)\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = AdamW(model.parameters(),lr = 0.01)  # learning rate\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr = 0.01)  # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class weights are [1.21614446 0.84909158] for [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "#compute the class weights\n",
    "class_weights = compute_class_weight(class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_labels),\n",
    "                                        y = train_labels \n",
    "                                     )\n",
    "print(\"class weights are {} for {}\".format(class_weights,np.unique(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights= torch.tensor(class_weights, dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "#criterion  = nn.CrossEntropyLoss(weight=weights) \n",
    "#criterion  = nn.CrossEntropyLoss() \n",
    "#criterion  = nn.BCELoss(weight=weights) \n",
    "#criterion  = nn.BCELoss() \n",
    "criterion  = nn.BCEWithLogitsLoss() \n",
    "\n",
    "metric = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_rnn_aa\n",
    "epoch_train_losses = [] \n",
    "epoch_valid_losses = [] \n",
    "epoch_train_metric = [] \n",
    "epoch_valid_metric = [] \n",
    "time_spent = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'privet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprivet\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'privet' is not defined"
     ]
    }
   ],
   "source": [
    "privet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, time spent: 130.21\n",
      "train_loss : 0.5025 val_loss : 0.5039\n",
      "train_accuracy : 0.93 val_accuracy : 0.93\n",
      "==================================================\n",
      "Epoch 2, time spent: 129.81\n",
      "train_loss : 0.5029 val_loss : 0.5053\n",
      "train_accuracy : 0.92 val_accuracy : 0.93\n",
      "==================================================\n",
      "Epoch 3, time spent: 130.27\n",
      "train_loss : 0.5029 val_loss : 0.5049\n",
      "train_accuracy : 0.93 val_accuracy : 0.94\n",
      "==================================================\n",
      "Epoch 4, time spent: 130.39\n",
      "train_loss : 0.5025 val_loss : 0.5042\n",
      "train_accuracy : 0.93 val_accuracy : 0.94\n",
      "==================================================\n",
      "Epoch 5, time spent: 130.37\n",
      "train_loss : 0.5023 val_loss : 0.5049\n",
      "train_accuracy : 0.92 val_accuracy : 0.94\n",
      "==================================================\n",
      "Epoch 6, time spent: 130.55\n",
      "train_loss : 0.5024 val_loss : 0.5064\n",
      "train_accuracy : 0.93 val_accuracy : 0.92\n",
      "==================================================\n",
      "Epoch 7, time spent: 132.17\n",
      "train_loss : 0.5020 val_loss : 0.5043\n",
      "train_accuracy : 0.93 val_accuracy : 0.94\n",
      "==================================================\n",
      "Epoch 8, time spent: 130.52\n",
      "train_loss : 0.5018 val_loss : 0.5037\n",
      "train_accuracy : 0.93 val_accuracy : 0.94\n",
      "==================================================\n",
      "Epoch 9, time spent: 130.50\n",
      "train_loss : 0.5017 val_loss : 0.5038\n",
      "train_accuracy : 0.93 val_accuracy : 0.93\n",
      "==================================================\n",
      "Epoch 10, time spent: 130.34\n",
      "train_loss : 0.5024 val_loss : 0.5040\n",
      "train_accuracy : 0.93 val_accuracy : 0.94\n",
      "==================================================\n",
      "Epoch 11, time spent: 130.30\n",
      "train_loss : 0.5019 val_loss : 0.5038\n",
      "train_accuracy : 0.93 val_accuracy : 0.94\n",
      "==================================================\n",
      "Epoch 12, time spent: 130.41\n",
      "train_loss : 0.5021 val_loss : 0.5046\n",
      "train_accuracy : 0.93 val_accuracy : 0.94\n",
      "==================================================\n",
      "Epoch 13, time spent: 131.50\n",
      "train_loss : 0.5025 val_loss : 0.5046\n",
      "train_accuracy : 0.93 val_accuracy : 0.94\n",
      "==================================================\n",
      "Epoch 14, time spent: 130.35\n",
      "train_loss : 0.5023 val_loss : 0.5044\n",
      "train_accuracy : 0.93 val_accuracy : 0.93\n",
      "==================================================\n",
      "Epoch 15, time spent: 130.51\n",
      "train_loss : 0.5023 val_loss : 0.5042\n",
      "train_accuracy : 0.93 val_accuracy : 0.93\n",
      "==================================================\n",
      "Epoch 16, time spent: 130.61\n",
      "train_loss : 0.5017 val_loss : 0.5038\n",
      "train_accuracy : 0.93 val_accuracy : 0.93\n",
      "==================================================\n",
      "Epoch 17, time spent: 130.53\n",
      "train_loss : 0.5019 val_loss : 0.5033\n",
      "train_accuracy : 0.93 val_accuracy : 0.93\n",
      "==================================================\n",
      "Epoch 18, time spent: 130.56\n",
      "train_loss : 0.5019 val_loss : 0.5043\n",
      "train_accuracy : 0.93 val_accuracy : 0.94\n",
      "==================================================\n",
      "Epoch 19, time spent: 130.39\n",
      "train_loss : 0.5015 val_loss : 0.5036\n",
      "train_accuracy : 0.93 val_accuracy : 0.94\n",
      "==================================================\n",
      "Epoch 20, time spent: 131.65\n",
      "train_loss : 0.5015 val_loss : 0.5037\n",
      "train_accuracy : 0.93 val_accuracy : 0.94\n",
      "==================================================\n",
      "Epoch 21, time spent: 130.30\n",
      "train_loss : 0.5009 val_loss : 0.5038\n",
      "train_accuracy : 0.93 val_accuracy : 0.93\n",
      "==================================================\n",
      "Epoch 22, time spent: 130.40\n",
      "train_loss : 0.5014 val_loss : 0.5043\n",
      "train_accuracy : 0.93 val_accuracy : 0.93\n",
      "==================================================\n",
      "Epoch 23, time spent: 130.33\n",
      "train_loss : 0.5011 val_loss : 0.5040\n",
      "train_accuracy : 0.93 val_accuracy : 0.94\n",
      "==================================================\n",
      "Epoch 24, time spent: 130.34\n",
      "train_loss : 0.5018 val_loss : 0.5049\n",
      "train_accuracy : 0.93 val_accuracy : 0.93\n",
      "==================================================\n",
      "Epoch 25, time spent: 131.70\n",
      "train_loss : 0.5017 val_loss : 0.5041\n",
      "train_accuracy : 0.93 val_accuracy : 0.93\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "model, epoch_train_losses, epoch_valid_losses, epoch_train_metric, epoch_valid_metric, time_spent = train_rnn_aa.train_BERT(25, model, \n",
    "        train_dataloader,\n",
    "        test_dataloader, \n",
    "        optimizer, \n",
    "        criterion,   \n",
    "        metric,              \n",
    "        epoch_train_losses,\n",
    "        epoch_valid_losses,\n",
    "        epoch_train_metric,\n",
    "        epoch_valid_metric,\n",
    "        time_spent, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/model_bert.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_dict({'epoch_train_losses':epoch_train_losses, \n",
    "                              'epoch_valid_losses': epoch_valid_losses, \n",
    "                              'epoch_train_metric': epoch_train_metric, \n",
    "                              'epoch_valid_metric': epoch_valid_metric, \n",
    "                               'time_spent': time_spent })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch_train_losses</th>\n",
       "      <th>epoch_valid_losses</th>\n",
       "      <th>epoch_train_metric</th>\n",
       "      <th>epoch_valid_metric</th>\n",
       "      <th>time_spent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.525405</td>\n",
       "      <td>0.508971</td>\n",
       "      <td>0.871188</td>\n",
       "      <td>0.922510</td>\n",
       "      <td>134.272626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511260</td>\n",
       "      <td>0.509225</td>\n",
       "      <td>0.905787</td>\n",
       "      <td>0.927812</td>\n",
       "      <td>129.507887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.508636</td>\n",
       "      <td>0.509464</td>\n",
       "      <td>0.912229</td>\n",
       "      <td>0.929393</td>\n",
       "      <td>129.753993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.508153</td>\n",
       "      <td>0.511557</td>\n",
       "      <td>0.913599</td>\n",
       "      <td>0.926933</td>\n",
       "      <td>130.030416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.507701</td>\n",
       "      <td>0.506522</td>\n",
       "      <td>0.914089</td>\n",
       "      <td>0.930323</td>\n",
       "      <td>130.200960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch_train_losses  epoch_valid_losses  epoch_train_metric  \\\n",
       "0            0.525405            0.508971            0.871188   \n",
       "1            0.511260            0.509225            0.905787   \n",
       "2            0.508636            0.509464            0.912229   \n",
       "3            0.508153            0.511557            0.913599   \n",
       "4            0.507701            0.506522            0.914089   \n",
       "\n",
       "   epoch_valid_metric  time_spent  \n",
       "0            0.922510  134.272626  \n",
       "1            0.927812  129.507887  \n",
       "2            0.929393  129.753993  \n",
       "3            0.926933  130.030416  \n",
       "4            0.930323  130.200960  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('data/result_bert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens_test_df['input_ids']\n",
    "#test_mask_tenzor = torch.tensor(tokens_test_df['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = []\n",
    "for batch_valid in test_dataloader:\n",
    "            batch_valid = [r.to(device) for r in batch_valid]            \n",
    "            inputs, mask, labels = batch_valid            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(inputs, mask).squeeze()\n",
    "            answer.append(output.to('cpu').squeeze())\n",
    "            #answer.append(output.to('cpu').squeeze().argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_list = []\n",
    "for i in range(0, len(answer)):\n",
    "    answer_list.append(answer[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10590"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_answer_list = []\n",
    "for i in answer_list:\n",
    "    for j in range(0, len(i)):\n",
    "        flat_answer_list.append(i[j])\n",
    "len(flat_answer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_df = pd.DataFrame.from_dict({'answer':flat_answer_list})\n",
    "answer_df['answer'] = answer_df['answer'].astype(int)\n",
    "answer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2929     0\n",
       "41238    1\n",
       "29580    0\n",
       "1844     1\n",
       "26928    1\n",
       "        ..\n",
       "32580    1\n",
       "48676    1\n",
       "53790    1\n",
       "49096    0\n",
       "26574    1\n",
       "Name: class, Length: 10590, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = test_labels.astype(int)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame([], columns = ['Model', 'time_sec', 'Accuracy', 'Precision', 'Recall', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_labels, answer_df['answer'])\n",
    "precision = precision_score(test_labels, answer_df['answer'], average='macro')\n",
    "recall = recall_score(test_labels, answer_df['answer'], average='macro')\n",
    "f1 = f1_score(test_labels, answer_df['answer'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([pd.DataFrame([{'Model':'12A: BERT', \n",
    "                                   'time_sec' : f'{sum(time_spent):.1f}', \n",
    "                                   'Accuracy' : f'{accuracy:.4f}', \n",
    "                                   'Precision' : f'{precision:.4f}', \n",
    "                                   'Recall' : f'{recall:.4f}', \n",
    "                                   'F1' : f'{f1:.4f}'\n",
    "                                   }],\n",
    "                                   columns=result.columns), result], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12A: BERT</td>\n",
       "      <td>7185.4</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model time_sec Accuracy Precision  Recall      F1\n",
       "0  12A: BERT   7185.4   0.4256    0.2128  0.5000  0.2985"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to file\n",
    "result.to_csv('data/bert_model_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
